# -*- coding: utf-8 -*-
"""Covid, phen, norm classification (95acc).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xr7F20k5JLpEdzFp-47t6YVpGFGMYJw2

# Kaggle prerequisites
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
files.upload()

!pip install -q kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

"""# Importing the libraries"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import os
import numpy as np
import shutil
import random
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.callbacks import ModelCheckpoint, EarlyStopping

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras import optimizers
from tensorflow.keras import applications
from keras.models import model_from_json

import matplotlib.pyplot as plt
import itertools
from sklearn.metrics import classification_report, confusion_matrix

from sklearn.metrics import accuracy_score

from keras.preprocessing import image

"""
#Downloading and Unzipping the datasets"""

!kaggle datasets download -d prashant268/chest-xray-covid19-pneumonia

!mkdir destination1

!unzip /content/chest-xray-covid19-pneumonia.zip -d destination1

"""#Splitting into test, train and calidation sets"""

make_dir ='/content/destination1/Data'
root_dir = '/content/destination1/Data/train'
classes_dir = ['COVID19','NORMAL','PNEUMONIA']

val_ratio = 0.1

for cls in classes_dir:

  os.makedirs(make_dir +'/val/' + cls)


    # Creating partitions of the data after shuffeling
  src = root_dir + '/'+ cls # Folder to copy images from

  allFileNames = os.listdir(src)
  np.random.shuffle(allFileNames)
  train_FileNames, val_FileNames = np.split(np.array(allFileNames),
                                                              [int(len(allFileNames)* (1 - val_ratio))])


  train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]
  val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]

  print('Total images: ', len(allFileNames))
  print('Training: ', len(train_FileNames))
  print('Validation: ', len(val_FileNames))

  # moving images

  for name in val_FileNames:
    shutil.move(name, make_dir +'/val/' + cls)

"""#Image Augmentation and preprocessing"""

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)
training_set = train_datagen.flow_from_directory('/content/destination1/Data/train',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical')

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory('/content/destination1/Data/val',
                                            target_size = (224, 224),
                                            batch_size = 8,
                                            class_mode = 'categorical',
                                            shuffle = False)

val_datagen = ImageDataGenerator(rescale = 1./255)
val_set = val_datagen.flow_from_directory('/content/destination1/Data/test',
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

"""# Building the CNN

### Initialising the CNN
"""

model = Sequential()

model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))

model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))

model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))


model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))

model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))

model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))


model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))

model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))

model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))


model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))

model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))

model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

model.add(Flatten())
model.add(Dense(units=512,activation="relu"))
model.add(Dense(units=1024,activation="relu"))
model.add(Dense(units=3, activation="softmax"))

opt = tf.keras.optimizers.Adam(learning_rate=0.0001)

model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

model.summary()

filepath = '/content/best_Model_weights.h5'

checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
# early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, mode='auto')

results = model.fit(x=training_set, validation_data= val_set, epochs=20,callbacks=checkpoint)

"""#Acc and Loss Plots"""

plt.plot(results.history["accuracy"])
plt.plot(results.history['val_accuracy'])
plt.plot(results.history['loss'])
plt.plot(results.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

"""#Grphical Conusion Matrix"""

def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):

    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.figure(figsize=(10,10))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm = np.around(cm, decimals=2)
        cm[np.isnan(cm)] = 0.0
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
        
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

target_names = []
for key in training_set.class_indices:
    target_names.append(key)

print(target_names)
Y_pred = model.predict_generator(test_set)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')

cm = confusion_matrix(test_set.classes, y_pred)
plot_confusion_matrix(cm, target_names, title='Confusion Matrix')

Y_pred

cm

y_pred

"""#Classification Report"""

test_steps_per_epoch = np.math.ceil(test_set.samples / test_set.batch_size)

predictions = model.predict(test_set, steps=test_steps_per_epoch)
# Get most likely class
predicted_classes = np.argmax(predictions, axis=1)

class_labels = list(test_set.class_indices.keys())

confusion_matrix(test_set.classes, predicted_classes)

predictions

predicted_classes

print(np.trace(confusion_matrix(test_set.classes, predicted_classes)))
accuracy_score(test_set.classes, predicted_classes)

print('Classification Report: ')
report = classification_report(test_set.classes, predicted_classes, target_names=class_labels)
print(report)

training_set.class_indices

# evaluate the model on test data
score = model.evaluate(test_set, verbose=2)
print ("%s: %.2f%%" % (model.metrics_names[1], score[1]*100))

"""# Making a single prediction"""

test_image = image.load_img('/content/COVID19(463).jpg', target_size = (224, 224))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
# predicted_classes= np.argmax(model.predict(test_image), axis=1)

result = model.predict(test_image)
training_set.class_indices
if result[0][0] == 1:
  prediction = 'COVID19'
elif result[0][1] ==1:
  prediction = 'NORMAL'
elif result[0][2] ==1:
  prediction = 'PNEUMONIA'

print(result)
